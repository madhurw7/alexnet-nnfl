{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1L7ijx4_plzX",
    "outputId": "67342e61-994f-455c-b1b7-b9621ebd492a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 29kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 39.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.28.1)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 35.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.3.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=5b168fc0eadd4dd305f35eba392200888f4c22066d7f8e0b8bd953194c4e6273\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorboard 2.2.1\n",
      "    Uninstalling tensorboard-2.2.1:\n",
      "      Successfully uninstalled tensorboard-2.2.1\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKmoZqGATEBJ"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9j00fkXKo0-f",
    "outputId": "0af261c9-5b5d-4c30-e070-f0384854a530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eB1SymK7TLsP",
    "outputId": "b220624c-16e8-40fe-c6a5-e4b242997aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ascIz7-pevEh",
    "outputId": "3ac20e9d-4b36-46a2-a01f-5d27e0977998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Akc4NI0_TNen",
    "outputId": "cf2274bd-a91f-4ac1-9481-e5efecb5273b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/nnfl-alexnet-data\n"
     ]
    }
   ],
   "source": [
    "%cd drive/'My Drive'/nnfl-alexnet-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5GOqsmuoVd4"
   },
   "outputs": [],
   "source": [
    "#load Data from Disk\n",
    "# valData = np.load('./valDataComplete.npz')\n",
    "inputVal = np.load('./valDataComplete.npz')['arr_0']\n",
    "outputVal = np.load('./valDataComplete.npz')['arr_1']\n",
    "\n",
    "# trainData = np.load('./trainDataComplete.npz')\n",
    "inputTrain = np.load('./trainDataComplete.npz')['arr_0']\n",
    "outputTrain = np.load('./trainDataComplete.npz')['arr_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xeg47Y2d8TA0"
   },
   "source": [
    "inMean = 112.69858580973307\n",
    "inStd = 70.93752549462194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiYbbMbv39Wr"
   },
   "outputs": [],
   "source": [
    "def getTrainingSample():\n",
    "    #wrapper to give data to the model in the desired API\n",
    "    return [inputTrain, outputTrain]\n",
    "\n",
    "def getValidationSample():\n",
    "    #wrapper to give data to the model in the desired API\n",
    "    return [inputVal, outputVal]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRCNrykTyiml"
   },
   "outputs": [],
   "source": [
    "class LRN2D(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
    "        super(LRN2D, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = K.shape(X)\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = K.square(X)\n",
    "        extra_channels = K.zeros((b, ch + 2 * half_n, r, c))\n",
    "        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],\n",
    "                                   input_sqr,\n",
    "                                   extra_channels[:, half_n + ch:, :, :]],\n",
    "                                  axis=1)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i + ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__,\n",
    "                  \"alpha\": self.alpha,\n",
    "                  \"k\": self.k,\n",
    "                  \"beta\": self.beta,\n",
    "                  \"n\": self.n}\n",
    "        base_config = super(LRN2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YresCjt0Tk_U"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQX8GILBTTJA"
   },
   "outputs": [],
   "source": [
    "def build(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(96, (11, 11), strides=(4, 4), padding='same', \n",
    "                                     activation='relu', use_bias = 1, \n",
    "                                     kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                     bias_initializer = 'zeros', input_shape=input_shape))\n",
    "    model.add(LRN2D())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(256, (5, 5),\n",
    "                                    activation='relu', use_bias = 1, \n",
    "                                    kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                    bias_initializer = 'ones'))\n",
    "    model.add(LRN2D())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', \n",
    "                                     activation='relu', use_bias = 1, \n",
    "                                     kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                     bias_initializer = 'zeros'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', \n",
    "                                     activation='relu', use_bias = 1, \n",
    "                                     kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                     bias_initializer = 'ones'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', \n",
    "                                     activation='relu', use_bias = 1, \n",
    "                                     kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                     bias_initializer = 'ones'))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu', use_bias = 1,\n",
    "                                    kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                    bias_initializer = 'ones'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu', use_bias = 1,\n",
    "                                    kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                    bias_initializer = 'ones'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax', use_bias = 1,\n",
    "                                    kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1e-2),\n",
    "                                    bias_initializer = 'ones'))\n",
    "    \n",
    "    model.summary()\n",
    "    tf.keras.utils.plot_model(model, to_file='architecture_imagenet.png')\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOOBM5p1UMi_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIvzn7lXUNEH"
   },
   "outputs": [],
   "source": [
    "def plot_graph(model, N):\n",
    "    \n",
    "    plt.figure(0)\n",
    "    plt.plot(np.arange(0, N), model.history['loss'], label='Training loss')\n",
    "    plt.plot(np.arange(0, N), model.history['val_loss'], label='Testing loss')\n",
    "    plt.title('Training vs Testing Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(np.arange(0, N), model.history['categorical_accuracy'], label='Top 1 Training Accuracy')\n",
    "    plt.plot(np.arange(0, N), model.history['val_categorical_accuracy'], label='Top 1 Testing Accuracy')\n",
    "    plt.title('Top 1 Training vs Testing Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(np.arange(0, N), model.history['TopKCategoricalAccuracy'], label='Top 5 Training Accuracy')\n",
    "    plt.plot(np.arange(0, N), model.history['val_TopKCategoricalAccuracy'], label='Top 5 Testing Accuracy')\n",
    "    plt.title('Top 5 Training vs Testing Acuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y37Ur-dMVuhQ"
   },
   "outputs": [],
   "source": [
    "def model_callbacks(name):\n",
    "    #checkpoint = tf.keras.callbacks.ModelCheckpoint(name, monitor = 'val_categorical_accuracy',\n",
    "    #                             mode = 'max', save_best_only = True, verbose = 1)\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', factor = 0.1,    \n",
    "                                  patience = 5, verbose = 1)\n",
    "    return [reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sovZxwQWVvKH",
    "outputId": "cabce20b-c8ac-470a-8cbe-07a84843a39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 96)        34944     \n",
      "_________________________________________________________________\n",
      "lr_n2d (LRN2D)               (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 7, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 256)         614656    \n",
      "_________________________________________________________________\n",
      "lr_n2d_1 (LRN2D)             (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               819400    \n",
      "=================================================================\n",
      "Total params: 25,546,312\n",
      "Trainable params: 25,546,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 400000 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "400000/400000 [==============================] - 35s 87us/sample - loss: 5.1658 - categorical_accuracy: 0.0137 - TopKCategoricalAccuracy: 0.0588 - val_loss: 4.9210 - val_categorical_accuracy: 0.0240 - val_TopKCategoricalAccuracy: 0.1110\n",
      "Epoch 2/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 4.7098 - categorical_accuracy: 0.0448 - TopKCategoricalAccuracy: 0.1582 - val_loss: 4.6917 - val_categorical_accuracy: 0.0610 - val_TopKCategoricalAccuracy: 0.1810\n",
      "Epoch 3/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 4.3498 - categorical_accuracy: 0.0816 - TopKCategoricalAccuracy: 0.2476 - val_loss: 4.5968 - val_categorical_accuracy: 0.0600 - val_TopKCategoricalAccuracy: 0.1980\n",
      "Epoch 4/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 3.9838 - categorical_accuracy: 0.1242 - TopKCategoricalAccuracy: 0.3348 - val_loss: 4.5776 - val_categorical_accuracy: 0.0760 - val_TopKCategoricalAccuracy: 0.2490\n",
      "Epoch 5/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 3.6240 - categorical_accuracy: 0.1737 - TopKCategoricalAccuracy: 0.4227 - val_loss: 4.7889 - val_categorical_accuracy: 0.0820 - val_TopKCategoricalAccuracy: 0.2510\n",
      "Epoch 6/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 3.2021 - categorical_accuracy: 0.2440 - TopKCategoricalAccuracy: 0.5260 - val_loss: 5.1784 - val_categorical_accuracy: 0.0600 - val_TopKCategoricalAccuracy: 0.1760\n",
      "Epoch 7/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 2.6827 - categorical_accuracy: 0.3453 - TopKCategoricalAccuracy: 0.6415 - val_loss: 5.4240 - val_categorical_accuracy: 0.0850 - val_TopKCategoricalAccuracy: 0.2360\n",
      "Epoch 8/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 2.1206 - categorical_accuracy: 0.4672 - TopKCategoricalAccuracy: 0.7509 - val_loss: 6.0331 - val_categorical_accuracy: 0.0790 - val_TopKCategoricalAccuracy: 0.2170\n",
      "Epoch 9/60\n",
      "399000/400000 [============================>.] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.5852 - TopKCategoricalAccuracy: 0.8374\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 1.6015 - categorical_accuracy: 0.5853 - TopKCategoricalAccuracy: 0.8375 - val_loss: 6.9539 - val_categorical_accuracy: 0.0840 - val_TopKCategoricalAccuracy: 0.2230\n",
      "Epoch 10/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 0.8259 - categorical_accuracy: 0.7945 - TopKCategoricalAccuracy: 0.9380 - val_loss: 6.6266 - val_categorical_accuracy: 0.0860 - val_TopKCategoricalAccuracy: 0.2270\n",
      "Epoch 11/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 0.8264 - categorical_accuracy: 0.8118 - TopKCategoricalAccuracy: 0.9473 - val_loss: 6.0887 - val_categorical_accuracy: 0.0970 - val_TopKCategoricalAccuracy: 0.2370\n",
      "Epoch 12/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 0.9254 - categorical_accuracy: 0.7982 - TopKCategoricalAccuracy: 0.9424 - val_loss: 5.9157 - val_categorical_accuracy: 0.0940 - val_TopKCategoricalAccuracy: 0.2460\n",
      "Epoch 13/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 0.9703 - categorical_accuracy: 0.7921 - TopKCategoricalAccuracy: 0.9401 - val_loss: 6.1883 - val_categorical_accuracy: 0.0820 - val_TopKCategoricalAccuracy: 0.2360\n",
      "Epoch 14/60\n",
      "399000/400000 [============================>.] - ETA: 0s - loss: 1.0002 - categorical_accuracy: 0.7845 - TopKCategoricalAccuracy: 0.9386\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 1.0004 - categorical_accuracy: 0.7844 - TopKCategoricalAccuracy: 0.9385 - val_loss: 5.8795 - val_categorical_accuracy: 0.0920 - val_TopKCategoricalAccuracy: 0.2350\n",
      "Epoch 15/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 1.5128 - categorical_accuracy: 0.7287 - TopKCategoricalAccuracy: 0.9159 - val_loss: 4.4888 - val_categorical_accuracy: 0.1150 - val_TopKCategoricalAccuracy: 0.2800\n",
      "Epoch 16/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 2.7627 - categorical_accuracy: 0.4198 - TopKCategoricalAccuracy: 0.7246 - val_loss: 4.3054 - val_categorical_accuracy: 0.1200 - val_TopKCategoricalAccuracy: 0.2910\n",
      "Epoch 17/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 3.5960 - categorical_accuracy: 0.2166 - TopKCategoricalAccuracy: 0.4864 - val_loss: 4.3209 - val_categorical_accuracy: 0.1050 - val_TopKCategoricalAccuracy: 0.2830\n",
      "Epoch 18/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 4.0528 - categorical_accuracy: 0.1369 - TopKCategoricalAccuracy: 0.3560 - val_loss: 4.4222 - val_categorical_accuracy: 0.0890 - val_TopKCategoricalAccuracy: 0.2660\n",
      "Epoch 19/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 4.3390 - categorical_accuracy: 0.1033 - TopKCategoricalAccuracy: 0.2891 - val_loss: 4.5705 - val_categorical_accuracy: 0.0810 - val_TopKCategoricalAccuracy: 0.2340\n",
      "Epoch 20/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 4.5659 - categorical_accuracy: 0.0836 - TopKCategoricalAccuracy: 0.2446 - val_loss: 4.7405 - val_categorical_accuracy: 0.0650 - val_TopKCategoricalAccuracy: 0.2070\n",
      "Epoch 21/60\n",
      "399000/400000 [============================>.] - ETA: 0s - loss: 4.7615 - categorical_accuracy: 0.0674 - TopKCategoricalAccuracy: 0.2096\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 4.7617 - categorical_accuracy: 0.0674 - TopKCategoricalAccuracy: 0.2095 - val_loss: 4.8937 - val_categorical_accuracy: 0.0500 - val_TopKCategoricalAccuracy: 0.1760\n",
      "Epoch 22/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 5.0318 - categorical_accuracy: 0.0592 - TopKCategoricalAccuracy: 0.1869 - val_loss: 5.1815 - val_categorical_accuracy: 0.0460 - val_TopKCategoricalAccuracy: 0.1680\n",
      "Epoch 23/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2303 - categorical_accuracy: 0.0557 - TopKCategoricalAccuracy: 0.1783 - val_loss: 5.2715 - val_categorical_accuracy: 0.0460 - val_TopKCategoricalAccuracy: 0.1670\n",
      "Epoch 24/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2832 - categorical_accuracy: 0.0507 - TopKCategoricalAccuracy: 0.1659 - val_loss: 5.2926 - val_categorical_accuracy: 0.0370 - val_TopKCategoricalAccuracy: 0.1190\n",
      "Epoch 25/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2951 - categorical_accuracy: 0.0340 - TopKCategoricalAccuracy: 0.1180 - val_loss: 5.2971 - val_categorical_accuracy: 0.0140 - val_TopKCategoricalAccuracy: 0.0700\n",
      "Epoch 26/60\n",
      "399000/400000 [============================>.] - ETA: 0s - loss: 5.2977 - categorical_accuracy: 0.0134 - TopKCategoricalAccuracy: 0.0571\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2977 - categorical_accuracy: 0.0134 - TopKCategoricalAccuracy: 0.0570 - val_loss: 5.2981 - val_categorical_accuracy: 0.0050 - val_TopKCategoricalAccuracy: 0.0390\n",
      "Epoch 27/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 5.2982 - categorical_accuracy: 0.0064 - TopKCategoricalAccuracy: 0.0326 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0250\n",
      "Epoch 28/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0052 - TopKCategoricalAccuracy: 0.0268 - val_loss: 5.2983 - val_categorical_accuracy: 0.0040 - val_TopKCategoricalAccuracy: 0.0200\n",
      "Epoch 29/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0254 - val_loss: 5.2983 - val_categorical_accuracy: 0.0070 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 30/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0049 - TopKCategoricalAccuracy: 0.0251 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 31/60\n",
      "399000/400000 [============================>.] - ETA: 0s - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0250\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0250 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 32/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0051 - TopKCategoricalAccuracy: 0.0250 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 33/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0250 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 34/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0051 - TopKCategoricalAccuracy: 0.0250 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 35/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0251 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 36/60\n",
      "399000/400000 [============================>.] - ETA: 0s - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0249\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0250 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0220\n",
      "Epoch 37/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0249 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0230\n",
      "Epoch 38/60\n",
      "400000/400000 [==============================] - 27s 67us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0251 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0230\n",
      "Epoch 39/60\n",
      "400000/400000 [==============================] - 27s 68us/sample - loss: 5.2983 - categorical_accuracy: 0.0050 - TopKCategoricalAccuracy: 0.0251 - val_loss: 5.2983 - val_categorical_accuracy: 0.0030 - val_TopKCategoricalAccuracy: 0.0230\n",
      "Epoch 40/60\n",
      "341000/400000 [========================>.....] - ETA: 4s - loss: 5.2983 - categorical_accuracy: 0.0051 - TopKCategoricalAccuracy: 0.0252WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy,TopKCategoricalAccuracy,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3509e08f73e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m history = model_tinynet.fit(inp, out, batch_size = batch_size, validation_data = (inp_test, out_test), \n\u001b[1;32m     24\u001b[0m                                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                       callbacks = model_callbacks('a'))\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mplot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# all the parameters\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "total_epochs = 60\n",
    "batch_size = 1000\n",
    "input_shape = (56, 56, 3)\n",
    "num_classes = 200\n",
    "\n",
    "inp = np.array(getTrainingSample()[0])\n",
    "out = np.array(getTrainingSample()[1])\n",
    "inp_test = np.array(getValidationSample()[0])\n",
    "out_test = np.array(getValidationSample()[1])\n",
    "\n",
    "# Training TinyNet\n",
    "model_tinynet = build(input_shape, num_classes)\n",
    "model_tinynet.compile(optimizer = tfa.optimizers.weight_decay_optimizers.SGDW(\n",
    "                        learning_rate=learning_rate, momentum=momentum, \n",
    "                        weight_decay=weight_decay, nesterov=True, name='SGDW'),\n",
    "                        loss='categorical_crossentropy', \n",
    "                        metrics=['categorical_accuracy', 'TopKCategoricalAccuracy'])\n",
    "\n",
    "history = model_tinynet.fit(inp, out, batch_size = batch_size, validation_data = (inp_test, out_test), \n",
    "                                      epochs = total_epochs, verbose=1,\n",
    "                                      callbacks = model_callbacks('a'))\n",
    "\n",
    "plot_graph(history, total_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rt0fYSQuVx6R"
   },
   "outputs": [],
   "source": [
    "x = getTrainingSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tEstImiuWEoz",
    "outputId": "4b494cd4-e4a1-4e8b-c9ba-a52f816242d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gYb1T9VEWIre",
    "outputId": "f193aacc-d12a-4311-d531-5a1acd3691f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "er_9fCylWKLK",
    "outputId": "fdd5c33d-f798-4603-af4c-f86cd923d6f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXCyojIMWMm_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "clean-alexnet-DataGen",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
